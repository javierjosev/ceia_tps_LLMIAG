{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs e IA Generativa\n",
    "\n",
    "## Routing con agentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se demuestran las capacidades de los agentes mediante el uso de LangChain y LangGraph. A partir del primer ejercicio, se desarrolló una clase denominada RAG, que funciona como una herramienta para los agentes. Se crean dos instancias de RAG, cada una asociada a un índice independiente en Pinecone y vinculada a un CV específico.\n",
    "Posteriormente, se implementan dos agentes distintos, cada uno con acceso exclusivo a uno de los RAGs previamente definidos. De esta manera, cada agente puede interactuar con su propio conjunto de información y generar respuestas contextualizadas en función del CV persistido en el índice.\n",
    "\n",
    "El objetivo de este trabajo es simplemente demostrar las capacidades de los agentes, ya que no tiene un fin práctico real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from RAG import RAG\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from pathlib import Path\n",
    "import os\n",
    "import operator\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import Tool\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan dos RAGs, uno para cada CV cargado. En este caso serán dos, uno para el CV de Javier y otro para el CV de Pablo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar la clase RAG\n",
    "groq_model=\"llama3-8b-8192\"\n",
    "embedding_model_name=\"all-MiniLM-L6-v2\"\n",
    "embedding_model_dim=384\n",
    "\n",
    "# Creo el index correspondiente al resume de Javier\n",
    "index_name_javier_resume = \"javier-resume-embeddings\"\n",
    "rag_javier_resume = RAG(embedding_model_name, embedding_model_dim, index_name_javier_resume, groq_model)\n",
    "path_javier_resume = Path('javier_resume/')\n",
    "rag_javier_resume.load_documents(path_javier_resume)\n",
    "\n",
    "# Creo el index correspondiente al resume de Pablo\n",
    "index_name_pablo_resume = \"pablo-resume-embeddings\"\n",
    "rag_pablo_resume = RAG(embedding_model_name, embedding_model_dim, index_name_pablo_resume, groq_model)\n",
    "path_pablo_resume = Path('pablo_resume/')\n",
    "rag_pablo_resume.load_documents(path_pablo_resume)\n",
    "\n",
    "\n",
    "# Registrar como herramienta al RAG Javier\n",
    "rag_tool_javier_langchain = Tool(\n",
    "    name=\"RAG_Tool_Javier\",\n",
    "    func=rag_javier_resume,\n",
    "    description=\"A RAG tool for CV data about Javier Villagra, leveraging Groq hardware and an LLM to retrieve and generate precise answers about individuals' work experience, education, and skills.\"\n",
    ")\n",
    "\n",
    "# Registrar como herramienta al RAG Pablo\n",
    "rag_tool_pablo_langchain = Tool(\n",
    "    name=\"RAG_Tool_Pablo\",\n",
    "    func=rag_pablo_resume,\n",
    "    description=\"A RAG tool for CV data about Pablo Segovia, leveraging Groq hardware and an LLM to retrieve and generate precise answers about individuals' work experience, education, and skills.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Inicializar un LLM base\n",
    "ChatGroq.api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la clase Agent. Esta misma clase será usada para ambos agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_groq)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_groq(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            # Mapero de la respuesta del tool\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan los dos agentes, uno para cada CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "javier_bot = Agent(llm, [rag_tool_javier_langchain], system=prompt)\n",
    "\n",
    "pablo_bot = Agent(llm, [rag_tool_pablo_langchain], system=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se genera una clase que actúa como wrapper de los agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentWrapper():\n",
    "\n",
    "    def __init__(self, javier_bot:Agent, pablo_bot:Agent):\n",
    "        self.javier_bot = javier_bot\n",
    "        self.pablo_bot = pablo_bot\n",
    "\n",
    "    def __get_agent_from_prompt(self, prompt: str) -> Agent:\n",
    "        prompt_lower = prompt.lower()\n",
    "        if 'javier' in prompt_lower or 'villagra' in prompt_lower:\n",
    "            return self.javier_bot\n",
    "        elif 'pablo' in prompt_lower or 'segovia' in prompt_lower:\n",
    "            return self.pablo_bot\n",
    "        else:\n",
    "            raise KeyError()\n",
    "        \n",
    "    def ask(self, message:str) -> str:\n",
    "        messages = [HumanMessage(content=message)]\n",
    "        agent = self.__get_agent_from_prompt(message)\n",
    "        result = agent.graph.invoke({\"messages\": messages})\n",
    "        return print(result['messages'][-1].content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se realizan consultas sobre ambos CVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'RAG_Tool_Javier', 'args': {'__arg1': 'Javier Villagra'}, 'id': 'call_ght0', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'RAG_Tool_Javier', 'args': {'__arg1': 'Java'}, 'id': 'call_48yc', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'RAG_Tool_Javier', 'args': {'__arg1': 'Java'}, 'id': 'call_w9mv', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Yes, Javier knows Java language programming.\n"
     ]
    }
   ],
   "source": [
    "abot = AgentWrapper(javier_bot, pablo_bot)\n",
    "\n",
    "abot.ask(message=\"Does Javier know Java language programming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'RAG_Tool_Pablo', 'args': {'__arg1': 'Java'}, 'id': 'call_msq2', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Based on the information provided, it seems that there is no direct connection between Pablo and Java as a programming language. The information available does not mention Java as part of Pablo's work or expertise. Therefore, it can be concluded that Pablo does not know Java language programming.\n"
     ]
    }
   ],
   "source": [
    "abot.ask(message=\"Does Pablo know Java language programming?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
